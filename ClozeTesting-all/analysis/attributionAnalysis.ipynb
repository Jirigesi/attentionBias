{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaConfig, RobertaForMaskedLM, RobertaTokenizer\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import javalang\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n",
    "from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients, LayerActivation\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer\n",
    "\n",
    "if torch.__version__ >= '1.7.0':\n",
    "    norm_fn = torch.linalg.norm\n",
    "else:\n",
    "    norm_fn = torch.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForMaskedLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "MODEL_CLASSES = {'roberta': (RobertaConfig, RobertaForMaskedLM, RobertaTokenizer)}\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES['roberta']\n",
    "config = config_class.from_pretrained('roberta-base')\n",
    "tokenizer = tokenizer_class.from_pretrained('roberta-base')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('microsoft/codebert-base-mlm', \n",
    "                                           output_attentions=True, output_hidden_states=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_token_id = tokenizer.pad_token_id # A token used for generating token reference\n",
    "sep_token_id = tokenizer.sep_token_id # A token used as a separator between question and text and it is also added to the end of the text.\n",
    "cls_token_id = tokenizer.cls_token_id # A token used for prepending to the concatenated question-text word sequence\n",
    "\n",
    "token_reference = TokenReferenceBase(reference_token_idx=ref_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 0, 50264)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id, tokenizer.sep_token_id, tokenizer.cls_token_id, tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cloze_words(filename, tokenizer):\n",
    "    with open(filename, 'r', encoding='utf-8') as fp:\n",
    "        words = fp.read().split('\\n')\n",
    "    idx2word = {tokenizer.encoder[w]: w for w in words}\n",
    "    return idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloze_results = []\n",
    "cloze_words_file = 'data/cloze-all/cloze_test_words.txt'\n",
    "file_path = 'data/cloze-all/java/clozeTest.json'\n",
    "\n",
    "idx2word = get_cloze_words(cloze_words_file, tokenizer)\n",
    "lines = json.load(open(file_path))\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40492\n"
     ]
    }
   ],
   "source": [
    "def read_answers(filename):\n",
    "    answers = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            answers[line.split('<CODESPLIT>')[0]] = line.split('<CODESPLIT>')[1]\n",
    "    return answers\n",
    "\n",
    "answer_file = 'evaluator/answers/java/answers.txt'\n",
    "answers = read_answers(answer_file)\n",
    "answer_list = list(answers.values())\n",
    "print(len(answer_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestSampleWithMaxPairLength = []\n",
    "bestSampleWithMaxPairLength_LEN =[]\n",
    "\n",
    "number_of_samples = 10\n",
    "for i in range(len(lines[:number_of_samples])):\n",
    "    code = ' '.join(lines[i]['pl_tokens'])\n",
    "    bestStr = \"<s> \" + code + \" </s>\"\n",
    "    bestLen = len(bestStr.split(\" \"))\n",
    "    bestSampleWithMaxPairLength.append(bestStr)\n",
    "    bestSampleWithMaxPairLength_LEN.append(bestLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths=[]\n",
    "codes=[]\n",
    "selected_answers = []\n",
    "\n",
    "for index, code in enumerate(bestSampleWithMaxPairLength):\n",
    "  l = len(tokenizer.tokenize(code))\n",
    "  if l<=256:\n",
    "    lengths.append(l)\n",
    "    codes.append(code)\n",
    "    selected_answers.append(answer_list[index])\n",
    "\n",
    "len(codes), len(selected_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract attribution score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / norm_fn(attributions)\n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids):\n",
    "    input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids)\n",
    "    ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids)\n",
    "    \n",
    "    return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_forward_func(input_embeddings, tokenized_text):\n",
    "    output = model(inputs_embeds=input_embeddings)\n",
    "    index = tokenized_text.index(tokenizer.mask_token_id)\n",
    "    if index > output.logits.shape[1]:\n",
    "        print(\"Length of outpu is {} and index is {}\".format(output.logits.shape[1], index))\n",
    "    output_list = output.logits[0][index]\n",
    "    output_list = output_list.unsqueeze(0)\n",
    "    \n",
    "    return output_list.max(1).values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fjiriges/anaconda3/envs/cuBERT/lib/python3.8/site-packages/captum/attr/_models/base.py:188: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'roberta.embeddings.word_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Average attribution on CLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "cls_data = np.zeros((12,12))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for code in tqdm(codes):\n",
    "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(code))\n",
    "        input_ids = torch.tensor([tokenized_text]).to(device)\n",
    "        reference_indices = token_reference.generate_reference(input_ids.shape[1], device=device).unsqueeze(0)\n",
    "\n",
    "        layer_attrs = []\n",
    "        layer_attn_mat = []\n",
    "        input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids, reference_indices)\n",
    "\n",
    "        for i in range(model.config.num_hidden_layers):\n",
    "            lc = LayerConductance(predict_forward_func, \n",
    "                                model.roberta.encoder.layer[i])\n",
    "            layer_attributions = lc.attribute(inputs=input_embeddings, \n",
    "                                                    baselines=ref_input_embeddings, \n",
    "                                                    additional_forward_args=(tokenized_text))\n",
    "            layer_attrs.append(summarize_attributions(layer_attributions[0]))\n",
    "            layer_attn_mat.append(layer_attributions[1])\n",
    "        # layer x seq_len\n",
    "        layer_attrs = torch.stack(layer_attrs)\n",
    "        # layer x batch x head x seq_len x seq_len\n",
    "        layer_attn_mat = torch.stack(layer_attn_mat)\n",
    "        for layer in range(12):\n",
    "            for head in range(12):\n",
    "                cls_data[layer][head] += layer_attn_mat[layer][0][head][:, 0:1].mean().cpu().detach().numpy()\n",
    "            \n",
    "CLS_atten = cls_data/len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.29757121e-08,  1.63888776e-07, -2.77009934e-06,\n",
       "         2.26214744e-06, -5.52203538e-07,  1.38852113e-07,\n",
       "        -4.90683995e-07,  9.46428062e-09,  1.74776503e-07,\n",
       "         4.10140203e-09,  6.29861288e-06, -2.12366336e-07],\n",
       "       [ 3.60767359e-07, -2.17151443e-06,  7.05822950e-08,\n",
       "        -1.21162116e-07, -5.03540059e-06,  9.24548914e-07,\n",
       "         5.71309341e-08, -2.54528085e-07,  8.93198973e-08,\n",
       "         2.13705974e-05, -4.75635428e-07,  2.11378501e-07],\n",
       "       [ 1.67830868e-06, -1.50289176e-06, -1.02237394e-06,\n",
       "         2.52465275e-06,  1.18492803e-06,  1.43955161e-06,\n",
       "        -1.50837164e-06,  3.54706079e-07,  1.09389004e-05,\n",
       "         1.39103494e-06,  1.15306639e-06,  1.19133960e-07],\n",
       "       [-2.22937385e-07, -5.61024658e-07, -1.54342132e-06,\n",
       "         9.32231796e-06, -5.96278724e-07,  4.47601837e-07,\n",
       "        -3.19015990e-08,  1.30412347e-06, -3.99118062e-06,\n",
       "        -5.20843457e-08,  7.00009177e-09,  2.76793514e-06],\n",
       "       [-4.97239374e-06, -2.28115541e-06,  1.76068104e-07,\n",
       "        -7.86287290e-08,  2.29442187e-06, -1.70242494e-06,\n",
       "         5.75178761e-06, -1.48109484e-06,  1.00011467e-06,\n",
       "         3.00048190e-06, -2.58586898e-06, -2.80749622e-08],\n",
       "       [-1.67323188e-08, -1.82332777e-06,  1.70789971e-06,\n",
       "        -1.97586562e-07, -2.04150603e-06,  2.26782561e-07,\n",
       "        -8.42665173e-06,  9.22792033e-07,  2.10418992e-06,\n",
       "         1.79654154e-07, -7.57798535e-08,  2.55808359e-07],\n",
       "       [ 7.87109627e-07,  2.40104644e-06,  3.22328208e-06,\n",
       "         1.21299692e-06, -7.17900501e-07, -5.98034221e-08,\n",
       "        -1.12544507e-07,  1.00990736e-07,  7.43274934e-07,\n",
       "        -8.35881693e-07, -8.23799110e-07, -4.51803534e-06],\n",
       "       [-1.93445640e-07, -5.17742066e-08, -5.43213289e-07,\n",
       "        -3.84907878e-07,  1.21199990e-06,  1.53626630e-06,\n",
       "         2.00151954e-06,  2.65350641e-08,  3.72863340e-08,\n",
       "        -1.53516744e-06,  8.88322410e-08, -3.12632979e-06],\n",
       "       [-2.17530290e-10,  5.29035550e-08,  9.24931053e-07,\n",
       "         5.94954429e-07,  7.62579648e-08,  9.56889609e-08,\n",
       "         1.34488521e-06, -1.48460691e-07, -2.45392373e-08,\n",
       "         8.02815261e-07,  1.29220158e-06,  7.36907887e-08],\n",
       "       [-6.56916721e-09,  1.43043498e-07, -1.03568761e-06,\n",
       "        -1.06225761e-06, -7.67566509e-08,  9.45843267e-08,\n",
       "        -1.20117547e-06, -1.17812255e-07,  3.34041771e-07,\n",
       "         3.53085223e-08,  8.93070767e-08,  9.24327736e-07],\n",
       "       [ 1.91044055e-08, -1.06321387e-07, -2.68687443e-07,\n",
       "         3.08572585e-07,  1.92731437e-08,  5.90582031e-07,\n",
       "         3.71638861e-06,  3.96007220e-07, -5.44792435e-07,\n",
       "         9.91188926e-08,  3.76694971e-06,  3.78353948e-08],\n",
       "       [-1.26388591e-06, -2.91520561e-07,  2.93985913e-06,\n",
       "         8.29378460e-07, -1.88602275e-07, -5.47229573e-08,\n",
       "         4.65204461e-07,  7.87721087e-06, -7.87057588e-08,\n",
       "         3.20107637e-08,  1.26635070e-07, -2.53675510e-08]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLS_atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [ [[] for col in range(12)] for row in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "cls_data = [ [list() for col in range(12)] for row in range(12)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for code in tqdm(codes):\n",
    "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(code))\n",
    "        input_ids = torch.tensor([tokenized_text]).to(device)\n",
    "        reference_indices = token_reference.generate_reference(input_ids.shape[1], device=device).unsqueeze(0)\n",
    "\n",
    "        layer_attrs = []\n",
    "        layer_attn_mat = []\n",
    "        input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids, reference_indices)\n",
    "\n",
    "        for i in range(model.config.num_hidden_layers):\n",
    "            lc = LayerConductance(predict_forward_func, \n",
    "                                model.roberta.encoder.layer[i])\n",
    "            layer_attributions = lc.attribute(inputs=input_embeddings, \n",
    "                                                    baselines=ref_input_embeddings, \n",
    "                                                    additional_forward_args=())\n",
    "            layer_attrs.append(summarize_attributions(layer_attributions[0]))\n",
    "            layer_attn_mat.append(layer_attributions[1])\n",
    "        # layer x seq_len\n",
    "        layer_attrs = torch.stack(layer_attrs)\n",
    "        # layer x batch x head x seq_len x seq_len\n",
    "        layer_attn_mat = torch.stack(layer_attn_mat)\n",
    "        for layer in range(12):\n",
    "            for head in range(12):\n",
    "                cls_data[layer][head].append(layer_attn_mat[layer][0][head][:, 0:1].mean().cpu().detach().numpy())\n",
    "            \n",
    "# CLS_atten = cls_data/len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(cls_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Average attribution put on SEP token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "sep_data = np.zeros((12,12))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for code in tqdm(codes):\n",
    "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(code))\n",
    "        input_ids = torch.tensor([tokenized_text]).to(device)\n",
    "        reference_indices = token_reference.generate_reference(input_ids.shape[1], device=device).unsqueeze(0)\n",
    "\n",
    "        layer_attrs = []\n",
    "        layer_attn_mat = []\n",
    "        input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids, reference_indices)\n",
    "\n",
    "        for i in range(model.config.num_hidden_layers):\n",
    "            lc = LayerConductance(predict_forward_func, \n",
    "                                model.roberta.encoder.layer[i])\n",
    "            layer_attributions = lc.attribute(inputs=input_embeddings, \n",
    "                                                    baselines=ref_input_embeddings, \n",
    "                                                    additional_forward_args=())\n",
    "            layer_attrs.append(summarize_attributions(layer_attributions[0]))\n",
    "            layer_attn_mat.append(layer_attributions[1])\n",
    "        # layer x seq_len\n",
    "        layer_attrs = torch.stack(layer_attrs)\n",
    "        # layer x batch x head x seq_len x seq_len\n",
    "        layer_attn_mat = torch.stack(layer_attn_mat)\n",
    "        for layer in range(12):\n",
    "          for head in range(12):\n",
    "            for each_sep_index in torch.where(input_ids[0]==2)[0].cpu().detach().numpy():\n",
    "              sep_data[layer][head] += layer_attn_mat[layer][0][head][:, each_sep_index].mean().cpu().detach().numpy() / len(torch.where(input_ids[0]==2)[0].cpu().detach().numpy())\n",
    "\n",
    "            \n",
    "SEP_atten = sep_data/len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12)\n",
      "[ 1.22738629e-06 -1.32907765e-07 -4.75614517e-06 -2.41541149e-06\n",
      " -9.75793593e-07  3.98978181e-07 -7.98725491e-07 -1.47497113e-07\n",
      "  4.01814727e-07 -1.09785690e-06 -3.58600239e-08 -2.69610463e-06]\n"
     ]
    }
   ],
   "source": [
    "print(SEP_atten.shape)\n",
    "SEP_atten_sum = np.sum(SEP_atten, axis=1)\n",
    "print(SEP_atten_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average attention on Syntactic Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syntax_types_for_code(code_snippet):\n",
    "  types = [\"[CLS]\"]\n",
    "  code = [\"<s>\"]\n",
    "  tree = list(javalang.tokenizer.tokenize(code_snippet))\n",
    "  \n",
    "  for i in tree:\n",
    "    j = str(i)\n",
    "    j = j.split(\" \")\n",
    "    if j[1] == '\"MASK\"':\n",
    "      types.append('[MASK]')\n",
    "      code.append('<mask>')\n",
    "    else:\n",
    "      types.append(j[0].lower())\n",
    "      code.append(j[1][1:-1])\n",
    "    \n",
    "  types.append(\"[SEP]\")\n",
    "  code.append(\"</s>\")\n",
    "  return np.array(types), ' '.join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_of_token_when_tokenized(code, types, tokenizer):\n",
    "  reindexed_types = []\n",
    "  start = 0\n",
    "  end = 0\n",
    "  for index, each_token in enumerate(code.split(\" \")):\n",
    "    tokenized_list = tokenizer.tokenize(each_token)\n",
    "    for i in range(len(tokenized_list)):\n",
    "      end += 1\n",
    "    reindexed_types.append((start, end-1))\n",
    "    start = end\n",
    "  return reindexed_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSyntaxAttributionScore(codes, tokenizer, syntaxType):\n",
    "  Instannce = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    number = 0 \n",
    "    failed_calculate = 0\n",
    "    for eachCode in tqdm(codes, desc=syntaxType):\n",
    "      identifier = [[[] for col in range(12)] for row in range(12)]\n",
    "      try: \n",
    "        cleancode = eachCode.replace(\"<s> \", \"\").replace(\" </s>\", \"\").replace('<mask>', 'MASK')\n",
    "        types, rewrote_code = get_syntax_types_for_code(cleancode)\n",
    "        # send input to model\n",
    "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(rewrote_code))\n",
    "        input_ids = torch.tensor([tokenized_text]).to(device)\n",
    "        # get reference indices\n",
    "        reference_indices = token_reference.generate_reference(input_ids.shape[1], device=device).unsqueeze(0)\n",
    "\n",
    "        layer_attrs = []\n",
    "        layer_attn_mat = []\n",
    "        input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids, reference_indices)\n",
    "        # get layer attribution\n",
    "        for i in range(model.config.num_hidden_layers):\n",
    "          lc = LayerConductance(predict_forward_func, \n",
    "                              model.roberta.encoder.layer[i])\n",
    "          layer_attributions = lc.attribute(inputs=input_embeddings, \n",
    "                                                  baselines=ref_input_embeddings, \n",
    "                                                  additional_forward_args=())\n",
    "          layer_attrs.append(summarize_attributions(layer_attributions[0]))\n",
    "          layer_attn_mat.append(layer_attributions[1])\n",
    "          \n",
    "        # layer x seq_len\n",
    "        layer_attrs = torch.stack(layer_attrs)\n",
    "        # layer x batch x head x seq_len x seq_len\n",
    "        layer_attn_mat = torch.stack(layer_attn_mat)\n",
    "        # get start and end index of each token\n",
    "        start_end = get_start_end_of_token_when_tokenized(rewrote_code, types, tokenizer)\n",
    "        if syntaxType in types:\n",
    "          number += 1\n",
    "        for layer in range(12):\n",
    "          for head in range(12):\n",
    "            for each_sep_index in np.where(types==syntaxType)[0]:\n",
    "              start_index, end_index = start_end[each_sep_index]\n",
    "              interim_value = layer_attn_mat[layer][0][head][:, start_index:end_index+1].mean().cpu().detach().numpy()\n",
    "              if np.isnan(interim_value):\n",
    "                  pass\n",
    "              else: \n",
    "                  identifier[layer][head].append(interim_value) \n",
    "      except:\n",
    "        failed_calculate += 1\n",
    "        \n",
    "      \n",
    "    print(\"failed calculate: \", failed_calculate)\n",
    "    identifier = identifier/number\n",
    "    \n",
    "  return identifier, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_list = ['annotation', 'basictype', 'boolean', \n",
    "          'decimalinteger', 'identifier', 'keyword',\n",
    "          'modifier', 'operator', 'separator', 'null',\n",
    "          'string', 'decimalfloatingpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "annotation: 100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "basictype: 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "boolean: 100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decimalinteger: 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "identifier: 100%|██████████| 6/6 [00:08<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keyword: 100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modifier: 100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "operator: 100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "separator: 100%|██████████| 6/6 [00:08<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "null: 100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "string: 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n",
      "/tmp/ipykernel_1685073/3664822754.py:51: RuntimeWarning: invalid value encountered in divide\n",
      "  identifier = identifier/number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decimalfloatingpoint: 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_attns = {}\n",
    "avg_attens_sum = {}\n",
    "syntax_frequenct = {}\n",
    "\n",
    "for syntax in syntax_list:\n",
    "    avg_attns[syntax] = np.zeros((12, 12))\n",
    "    avg_attns[syntax], syntax_frequenct[syntax] = getSyntaxAttributionScore(codes, tokenizer, syntax)\n",
    "    avg_attens_sum[syntax] = np.sum(avg_attns[syntax], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInstanceSyntaxAttributionScore(codes, tokenizer, syntaxType):\n",
    "  instance = []\n",
    "  number = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for eachCode in tqdm(codes, desc=syntaxType):\n",
    "      identifier = [[[] for col in range(12)] for row in range(12)]\n",
    "      cleancode = eachCode.replace(\"<s> \", \"\").replace(\" </s>\", \"\").replace('<mask>', 'MASK')\n",
    "      types, rewrote_code = get_syntax_types_for_code(cleancode)\n",
    "      # send input to model\n",
    "      tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(rewrote_code))\n",
    "      input_ids = torch.tensor([tokenized_text]).to(device)\n",
    "      # get reference indices\n",
    "      reference_indices = token_reference.generate_reference(input_ids.shape[1], device=device).unsqueeze(0)\n",
    "\n",
    "      layer_attrs = []\n",
    "      layer_attn_mat = []\n",
    "      input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(input_ids, reference_indices)\n",
    "      # get layer attribution\n",
    "      for i in range(model.config.num_hidden_layers):\n",
    "        lc = LayerConductance(predict_forward_func, \n",
    "                            model.roberta.encoder.layer[i])\n",
    "        layer_attributions = lc.attribute(inputs=input_embeddings, \n",
    "                                                baselines=ref_input_embeddings, \n",
    "                                                additional_forward_args=(tokenized_text))\n",
    "        layer_attrs.append(summarize_attributions(layer_attributions[0]))\n",
    "        layer_attn_mat.append(layer_attributions[1])\n",
    "        \n",
    "      # layer x seq_len\n",
    "      layer_attrs = torch.stack(layer_attrs)\n",
    "      # layer x batch x head x seq_len x seq_len\n",
    "      layer_attn_mat = torch.stack(layer_attn_mat)\n",
    "      # get start and end index of each token\n",
    "      start_end = get_start_end_of_token_when_tokenized(rewrote_code, types, tokenizer)\n",
    "      if syntaxType in types:\n",
    "        number += 1\n",
    "      for layer in range(12):\n",
    "        for head in range(12):\n",
    "          for each_sep_index in np.where(types==syntaxType)[0]:\n",
    "            start_index, end_index = start_end[each_sep_index]\n",
    "            interim_value = layer_attn_mat[layer][0][head][:, start_index:end_index+1].mean().cpu().detach().numpy()\n",
    "            if np.isnan(interim_value):\n",
    "                pass\n",
    "            else: \n",
    "                identifier[layer][head].append(interim_value)\n",
    "                \n",
    "      if np.array(identifier).shape[2] != 0:\n",
    "        instance.append(identifier)\n",
    "\n",
    "    \n",
    "  return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "annotation: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n",
      "modifier: 100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n",
      "operator: 100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n"
     ]
    }
   ],
   "source": [
    "syntax_list = ['annotation','modifier', 'operator']\n",
    "avg_attns = {}\n",
    "for syntax in syntax_list:\n",
    "    avg_attns[syntax] = getInstanceSyntaxAttributionScore(codes, \n",
    "                                                            tokenizer, \n",
    "                                                            syntax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> @ Override public int peekBit ( ) throws AACException { int ret ; if ( bitsCached > 0 ) { ret = ( cache >> ( bitsCached - 1 ) ) & 1 ; } else { final int word = readCache ( true ) ; ret = ( <mask> >> WORD_BITS - 1 ) & 1 ; } return ret ; } </s>'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_attns['annotation']), len(avg_attns['modifier']), len(avg_attns['operator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = avg_attns['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(avg_attns['operator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = avg_attns['operator'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuBERT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8492d8711f92acbd6f1f5de70669e0e0dfa9ae8288673c2cd77f66771fab39c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
