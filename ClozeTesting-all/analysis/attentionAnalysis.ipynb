{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaConfig, RobertaForMaskedLM, RobertaTokenizer\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import javalang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {'roberta': (RobertaConfig, RobertaForMaskedLM, RobertaTokenizer)}\n",
    "\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES['roberta']\n",
    "config = config_class.from_pretrained('roberta-base')\n",
    "tokenizer = tokenizer_class.from_pretrained('roberta-base')\n",
    "\n",
    "model = RobertaForMaskedLM.from_pretrained('microsoft/codebert-base-mlm', \n",
    "                                           output_attentions=True, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 50264)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<s>', '</s>', '<mask>')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token, tokenizer.sep_token, tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloze_results = []\n",
    "cloze_words_file = 'data/cloze-all/cloze_test_words.txt'\n",
    "file_path = 'data/cloze-all/java/clozeTest.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cloze_words(filename, tokenizer):\n",
    "    with open(filename, 'r', encoding='utf-8') as fp:\n",
    "        words = fp.read().split('\\n')\n",
    "    idx2word = {tokenizer.encoder[w]: w for w in words}\n",
    "    return idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = get_cloze_words(cloze_words_file, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40492"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = json.load(open(file_path))\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_answers(filename):\n",
    "    answers = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.strip()\n",
    "            answers[line.split('<CODESPLIT>')[0]] = line.split('<CODESPLIT>')[1]\n",
    "    return answers\n",
    "\n",
    "answer_file = 'evaluator/answers/java/answers.txt'\n",
    "answers = read_answers(answer_file)\n",
    "answer_list = list(answers.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_word = idx2word[predict_word_id]\n",
    "# print('Predicted word: {}'.format(predict_word))\n",
    "# print('Ground truth word: {}'.format(answers['all-1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestSampleWithMaxPairLength = []\n",
    "bestSampleWithMaxPairLength_LEN =[]\n",
    "\n",
    "number_of_samples = 100\n",
    "for i in range(len(lines[:number_of_samples])):\n",
    "    code = ' '.join(lines[i]['pl_tokens'])\n",
    "    bestStr = \"<s> \" + code + \" </s>\"\n",
    "    bestLen = len(bestStr.split(\" \"))\n",
    "    bestSampleWithMaxPairLength.append(bestStr)\n",
    "    bestSampleWithMaxPairLength_LEN.append(bestLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths=[]\n",
    "codes=[]\n",
    "selected_answers = []\n",
    "\n",
    "for index, code in enumerate(bestSampleWithMaxPairLength):\n",
    "  l = len(tokenizer.tokenize(code))\n",
    "  if l<=256:\n",
    "    lengths.append(l)\n",
    "    codes.append(code)\n",
    "    selected_answers.append(answer_list[index])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 85)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(codes), len(selected_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = codes[0]\n",
    "with torch.no_grad():\n",
    "\n",
    "    tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(code))\n",
    "    input_ids = torch.tensor([tokenized_text])\n",
    "    output_from_model = model(input_ids)\n",
    "\n",
    "    _attention = output_from_model[\"attentions\"]# attention shape is layers, batchsize, heads, tokenLen, tokenLen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 78, 78])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_attention[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Javalang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree = list(javalang.tokenizer.tokenize(codes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, Operator \"<\" line 1, position 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tree), tree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(codes[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Average attention on CLS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:03<00:00, 24.20it/s]\n"
     ]
    }
   ],
   "source": [
    "cls_data = np.zeros((12,12))\n",
    "\n",
    "with torch.no_grad():\n",
    "  for eachCode in tqdm(codes):\n",
    "    tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(eachCode))[:512]\n",
    "    input_ids = torch.tensor([tokenized_text])\n",
    "    output_from_model = model(input_ids)\n",
    "    \n",
    "    _attention = output_from_model[\"attentions\"]# attention shape is layers, batchsize, heads, tokenLen, tokenLen\n",
    "    \n",
    "    for layer in range(12):\n",
    "      for head in range(12):\n",
    "        cls_data[layer][head] += _attention[layer][0][head][:, 0:1].mean().cpu().detach().numpy() \n",
    "\n",
    "CLS_atten = cls_data/len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12)\n",
      "[0.53873959 5.2101759  5.69606181 5.00920714 3.93256064 4.73496921\n",
      " 5.23256336 5.21673604 7.89330531 8.38361245 8.12879069 5.91060665]\n"
     ]
    }
   ],
   "source": [
    "print(CLS_atten.shape)\n",
    "CLS_atten_sum = np.sum(CLS_atten, axis=1)\n",
    "print(CLS_atten_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Average attention put on SEP token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:03<00:00, 24.83it/s]\n"
     ]
    }
   ],
   "source": [
    "sep_data = np.zeros((12,12))\n",
    "\n",
    "with torch.no_grad():\n",
    "  for eachCode in tqdm(codes):\n",
    "    tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(eachCode))\n",
    "    # index = inputs.index(tokenizer.mask_token_id)\n",
    "    inputs_id = torch.tensor([tokenized_text])\n",
    "    output_from_model = model(inputs_id)\n",
    "    \n",
    "    _attention = output_from_model[\"attentions\"]# attention shape is layers, batchsize, heads, tokenLen, tokenLen\n",
    "    \n",
    "    for layer in range(12):\n",
    "      for head in range(12):\n",
    "        for each_sep_index in torch.where(inputs_id[0]==2)[0].cpu().detach().numpy():\n",
    "          sep_data[layer][head] += _attention[layer][0][head][:, each_sep_index].mean().cpu().detach().numpy() \n",
    "\n",
    "SEP_atten = sep_data/len(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12)\n",
      "[0.1957119  0.13042349 0.0988445  0.14585112 0.21771341 0.21395908\n",
      " 0.14760725 0.114327   0.11055515 0.06455206 0.06105491 0.04995303]\n"
     ]
    }
   ],
   "source": [
    "print(SEP_atten.shape)\n",
    "SEP_atten_sum = np.sum(SEP_atten, axis=1)\n",
    "print(SEP_atten_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average attention on Syntactic Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syntax_types_for_code(code_snippet):\n",
    "  types = [\"[CLS]\"]\n",
    "  code = [\"<s>\"]\n",
    "  tree = list(javalang.tokenizer.tokenize(code_snippet))\n",
    "  \n",
    "  for i in tree:\n",
    "    j = str(i)\n",
    "    j = j.split(\" \")\n",
    "    if j[1] == '\"MASK\"':\n",
    "      types.append('[MASK]')\n",
    "      code.append('<mask>')\n",
    "    else:\n",
    "      types.append(j[0].lower())\n",
    "      code.append(j[1][1:-1])\n",
    "    \n",
    "  types.append(\"[SEP]\")\n",
    "  code.append(\"</s>\")\n",
    "  return np.array(types), ' '.join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_end_of_token_when_tokenized(code, types, tokenizer):\n",
    "  reindexed_types = []\n",
    "  start = 0\n",
    "  end = 0\n",
    "  for index, each_token in enumerate(code.split(\" \")):\n",
    "    tokenized_list = tokenizer.tokenize(each_token)\n",
    "    for i in range(len(tokenized_list)):\n",
    "      end += 1\n",
    "    reindexed_types.append((start, end-1))\n",
    "    start = end\n",
    "  return reindexed_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSyntaxAttentionScore(codes, tokenizer, syntaxType):\n",
    "\n",
    "  with torch.no_grad():\n",
    "    identifier = np.zeros((12,12))\n",
    "    number = 0 \n",
    "    failed_calculate = 0\n",
    "    for eachCode in tqdm(codes, desc=syntaxType):\n",
    "      try: \n",
    "        cleancode = eachCode.replace(\"<s> \", \"\").replace(\" </s>\", \"\").replace('<mask>', 'MASK')\n",
    "        types, rewrote_code = get_syntax_types_for_code(cleancode)\n",
    "        # send input to model\n",
    "        tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(rewrote_code))\n",
    "        input_ids = torch.tensor([tokenized_text])\n",
    "        output_from_model = model(input_ids)\n",
    "        # get attention from model\n",
    "        _attention = output_from_model[\"attentions\"]# attention shape is layers, batchsize, heads, tokenLen, tokenLen\n",
    "        # get start and end index of each token\n",
    "        start_end = get_start_end_of_token_when_tokenized(rewrote_code, types, tokenizer)\n",
    "        if syntaxType in types:\n",
    "          number += 1\n",
    "        for layer in range(12):\n",
    "          for head in range(12):\n",
    "            for each_sep_index in np.where(types==syntaxType)[0]:\n",
    "              start_index, end_index = start_end[each_sep_index]\n",
    "              interim_value = _attention[layer][0][head][:, start_index:end_index+1].mean().cpu().detach().numpy()\n",
    "              if np.isnan(interim_value):\n",
    "                  pass\n",
    "              else: \n",
    "                  identifier[layer][head] += interim_value\n",
    "      except:\n",
    "        failed_calculate += 1\n",
    "    print(\"failed calculate: \", failed_calculate)\n",
    "                \n",
    "    identifier = identifier/number\n",
    "  return identifier, number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_list = ['annotation', 'basictype', 'boolean', \n",
    "          'decimalinteger', 'identifier', 'keyword',\n",
    "          'modifier', 'operator', 'separator', 'null',\n",
    "          'string', 'decimalfloatingpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "annotation: 100%|██████████| 85/85 [00:03<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "basictype: 100%|██████████| 85/85 [00:02<00:00, 30.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "boolean: 100%|██████████| 85/85 [00:02<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decimalinteger: 100%|██████████| 85/85 [00:02<00:00, 32.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "identifier: 100%|██████████| 85/85 [00:07<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keyword: 100%|██████████| 85/85 [00:03<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modifier: 100%|██████████| 85/85 [00:02<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "operator: 100%|██████████| 85/85 [00:03<00:00, 21.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "separator: 100%|██████████| 85/85 [00:09<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "null: 100%|██████████| 85/85 [00:02<00:00, 34.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "string: 100%|██████████| 85/85 [00:02<00:00, 33.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decimalfloatingpoint: 100%|██████████| 85/85 [00:02<00:00, 37.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_attns = {}\n",
    "avg_attens_sum = {}\n",
    "syntax_frequenct = {}\n",
    "\n",
    "for syntax in syntax_list:\n",
    "    avg_attns[syntax] = np.zeros((12, 12))\n",
    "    avg_attns[syntax], syntax_frequenct[syntax] = getSyntaxAttentionScore(codes, tokenizer, syntax)\n",
    "    avg_attens_sum[syntax] = np.sum(avg_attns[syntax], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split based on corrrect and incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_precition_index = []\n",
    "misprediction_index = []\n",
    "\n",
    "for i, code in enumerate(codes): \n",
    "    tokenized_text = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(code))\n",
    "    index = tokenized_text.index(tokenizer.mask_token_id)\n",
    "    input_ids = torch.tensor([tokenized_text])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(input_ids)[0]\n",
    "        score_list = scores[0][index]\n",
    "        word_index = torch.LongTensor(list(idx2word.keys()))\n",
    "        word_index = torch.zeros(score_list.shape[0]).scatter(0, word_index, 1)\n",
    "        score_list = score_list + (1-word_index) * -1e6\n",
    "        predict_word_id = torch.argmax(score_list).data.tolist()\n",
    "    \n",
    "    predict_word = idx2word[predict_word_id]\n",
    "    \n",
    "    if predict_word == selected_answers[i]:\n",
    "        correct_precition_index.append(i)\n",
    "    else:\n",
    "        misprediction_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 11)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_precition_index), len(misprediction_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_codes = []\n",
    "mispredic_codes = []\n",
    "\n",
    "for i in correct_precition_index:\n",
    "    correct_codes.append(codes[i])\n",
    "    \n",
    "for i in misprediction_index:\n",
    "    mispredic_codes.append(codes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "annotation: 100%|██████████| 74/74 [00:02<00:00, 30.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "basictype: 100%|██████████| 74/74 [00:02<00:00, 33.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "boolean: 100%|██████████| 74/74 [00:02<00:00, 36.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decimalinteger: 100%|██████████| 74/74 [00:02<00:00, 33.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "identifier: 100%|██████████| 74/74 [00:06<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keyword: 100%|██████████| 74/74 [00:03<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modifier: 100%|██████████| 74/74 [00:02<00:00, 26.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "operator: 100%|██████████| 74/74 [00:03<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "separator: 100%|██████████| 74/74 [00:08<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "null: 100%|██████████| 74/74 [00:02<00:00, 32.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "string: 100%|██████████| 74/74 [00:02<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decimalfloatingpoint: 100%|██████████| 74/74 [00:02<00:00, 36.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_avg_attns = {}\n",
    "correct_avg_attens_sum = {}\n",
    "correct_syntax_frequenct = {}\n",
    "\n",
    "for syntax in syntax_list:\n",
    "    correct_avg_attns[syntax] = np.zeros((12, 12))\n",
    "    correct_avg_attns[syntax], correct_syntax_frequenct[syntax] = getSyntaxAttentionScore(correct_codes, tokenizer, syntax)\n",
    "    correct_avg_attens_sum[syntax] = np.sum(correct_avg_attns[syntax], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "annotation: 100%|██████████| 11/11 [00:00<00:00, 22.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "basictype: 100%|██████████| 11/11 [00:00<00:00, 29.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "boolean: 100%|██████████| 11/11 [00:00<00:00, 31.81it/s]\n",
      "/tmp/ipykernel_1568051/3865230560.py:34: RuntimeWarning: invalid value encountered in divide\n",
      "  identifier = identifier/number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decimalinteger: 100%|██████████| 11/11 [00:00<00:00, 30.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "identifier: 100%|██████████| 11/11 [00:01<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keyword: 100%|██████████| 11/11 [00:00<00:00, 27.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modifier: 100%|██████████| 11/11 [00:00<00:00, 29.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "operator: 100%|██████████| 11/11 [00:00<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "separator: 100%|██████████| 11/11 [00:01<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "null: 100%|██████████| 11/11 [00:00<00:00, 35.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "string: 100%|██████████| 11/11 [00:00<00:00, 34.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "decimalfloatingpoint: 100%|██████████| 11/11 [00:00<00:00, 38.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed calculate:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mispredict_avg_attns = {}\n",
    "mispredict_avg_attens_sum = {}\n",
    "mispredict_syntax_frequenct = {}\n",
    "\n",
    "for syntax in syntax_list:\n",
    "    mispredict_avg_attns[syntax] = np.zeros((12, 12))\n",
    "    mispredict_avg_attns[syntax], mispredict_syntax_frequenct[syntax] = getSyntaxAttentionScore(mispredic_codes, tokenizer, syntax)\n",
    "    mispredict_avg_attens_sum[syntax] = np.sum(mispredict_avg_attns[syntax], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation\n",
      "Ttest_indResult(statistic=3.447045271752126, pvalue=0.0022979045790702934)\n",
      "-----------------\n",
      "basictype\n",
      "Ttest_indResult(statistic=3.865915629913053, pvalue=0.0008359468076887228)\n",
      "-----------------\n",
      "boolean\n",
      "Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "-----------------\n",
      "decimalinteger\n",
      "Ttest_indResult(statistic=6.582215566506413, pvalue=1.2791377235426926e-06)\n",
      "-----------------\n",
      "identifier\n",
      "Ttest_indResult(statistic=-0.627945912747651, pvalue=0.5365039292636904)\n",
      "-----------------\n",
      "keyword\n",
      "Ttest_indResult(statistic=0.5595072193479274, pvalue=0.5814677909015604)\n",
      "-----------------\n",
      "modifier\n",
      "Ttest_indResult(statistic=-1.2976000912130323, pvalue=0.20786655274103427)\n",
      "-----------------\n",
      "operator\n",
      "Ttest_indResult(statistic=0.5761339491592351, pvalue=0.5703723068155411)\n",
      "-----------------\n",
      "separator\n",
      "Ttest_indResult(statistic=-0.018223083697325476, pvalue=0.9856251496106448)\n",
      "-----------------\n",
      "null\n",
      "Ttest_indResult(statistic=-1.0264636168881236, pvalue=0.3158275780621145)\n",
      "-----------------\n",
      "string\n",
      "Ttest_indResult(statistic=-2.1342642848641553, pvalue=0.044212993285999945)\n",
      "-----------------\n",
      "decimalfloatingpoint\n",
      "Ttest_indResult(statistic=nan, pvalue=nan)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.03177469619889501, pvalue=0.974938237839359)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "# read data from a pick file \n",
    "file1 = \"results/CLS_atten_sum_correct.pkl\"\n",
    "file2 = \"results/CLS_atten_sum_misprediction.pkl\"\n",
    "\n",
    "correct_CLS = pickle.load(open(file1, \"rb\"))\n",
    "mispredict_CLS = pickle.load(open(file2, \"rb\"))\n",
    "\n",
    "stats.ttest_ind(correct_CLS, mispredict_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.5376287728995854, pvalue=0.5962304462821135)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from a pick file \n",
    "file1 = \"results/SEP_atten_sum_correct.pkl\"\n",
    "file2 = \"results/SEP_atten_sum_misprediction.pkl\"\n",
    "\n",
    "correct_CLS = pickle.load(open(file1, \"rb\"))\n",
    "mispredict_CLS = pickle.load(open(file2, \"rb\"))\n",
    "\n",
    "stats.ttest_ind(correct_CLS, mispredict_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# read data from a pick file \n",
    "file1 = \"results/syntax_atten_attention_correct.pkl\"\n",
    "file2 = \"results/syntax_atten_attention_misprediction.pkl\"\n",
    "\n",
    "correct_Syntax = pickle.load(open(file1, \"rb\"))\n",
    "mispredict_Syntax = pickle.load(open(file2, \"rb\"))\n",
    "\n",
    "# stats.ttest_ind(correct_CLS, mispredict_CLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation\n",
      "Ttest_indResult(statistic=-0.10900912901747421, pvalue=0.9141834332621221)\n",
      "-----------------\n",
      "basictype\n",
      "Ttest_indResult(statistic=0.4417422652789735, pvalue=0.6629873183982515)\n",
      "-----------------\n",
      "boolean\n",
      "Ttest_indResult(statistic=0.380070647429576, pvalue=0.7075375418955014)\n",
      "-----------------\n",
      "decimalinteger\n",
      "Ttest_indResult(statistic=0.6374880193760781, pvalue=0.5303862769151588)\n",
      "-----------------\n",
      "identifier\n",
      "Ttest_indResult(statistic=0.04539532784516388, pvalue=0.9642017468560653)\n",
      "-----------------\n",
      "keyword\n",
      "Ttest_indResult(statistic=0.2467891018367265, pvalue=0.8073597443604594)\n",
      "-----------------\n",
      "modifier\n",
      "Ttest_indResult(statistic=-0.10819073376114986, pvalue=0.9148250755338021)\n",
      "-----------------\n",
      "operator\n",
      "Ttest_indResult(statistic=0.23067892868031312, pvalue=0.819695913827764)\n",
      "-----------------\n",
      "separator\n",
      "Ttest_indResult(statistic=0.21227993166624043, pvalue=0.8338431361591297)\n",
      "-----------------\n",
      "null\n",
      "Ttest_indResult(statistic=-0.2872184961987086, pvalue=0.776632943548014)\n",
      "-----------------\n",
      "string\n",
      "Ttest_indResult(statistic=-0.382062462095805, pvalue=0.7060807478321387)\n",
      "-----------------\n",
      "decimalfloatingpoint\n",
      "Ttest_indResult(statistic=0.9225094670623352, pvalue=0.36627010410556626)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "for syntax in syntax_list:\n",
    "    print(syntax)\n",
    "    print(stats.ttest_ind(correct_Syntax[syntax], mispredict_Syntax[syntax]))\n",
    "    print(\"-----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuBERT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8492d8711f92acbd6f1f5de70669e0e0dfa9ae8288673c2cd77f66771fab39c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
