{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_sitter import Language, Parser\n",
    "import javalang\n",
    "import numpy as np \n",
    "\n",
    "Language.build_library(\n",
    "\t# Store the library in the `build` directory\n",
    "\t'build/my-languages.so',\n",
    "\t\n",
    "\t# Include one or more languages\n",
    "\t[\n",
    "\t\t'/Users/jirigesi/Documents/tree-sitter-java'\n",
    "\t]\n",
    ")\n",
    "\n",
    "JAVA_LANGUAGE = Language('build/my-languages.so', 'java')\n",
    "parser = Parser()\n",
    "\n",
    "parser.set_language(JAVA_LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse(node,depth=0):\n",
    "    declaration = {}\n",
    "    stack = []\n",
    "    stack.append(node)\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if ('declaration' in node.type and node.type != \"local_variable_declaration\") or 'if_statement' in node.type or 'else' in node.type:\n",
    "            data = code[node.start_byte:node.end_byte].split('{')[0].strip().split(' ')\n",
    "            if node.type in declaration:\n",
    "                declaration[node.type].append(data)\n",
    "            else:\n",
    "                declaration[node.type] = [data]\n",
    "        for child in node.children:\n",
    "            stack.append(child)\n",
    "    return declaration\n",
    "\n",
    "def label_tokens(token_list, declaration):\n",
    "    types = [] \n",
    "    for token in token_list:\n",
    "        flag = False\n",
    "        for key in declaration:\n",
    "            for value in declaration[key]:\n",
    "                if token in value:\n",
    "                    types.append(key)\n",
    "                    flag = True\n",
    "                    break\n",
    "            if flag:\n",
    "                break\n",
    "        if not flag:\n",
    "            types.append(\"other\")\n",
    "    return types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extended_types(token_list, types):\n",
    "    tree = list(javalang.tokenizer.tokenize(\" \".join(token_list)))\n",
    "    code = ' '.join(token_list)\n",
    "    right = 0\n",
    "    left = 0\n",
    "    postion_mapping = [] \n",
    "\n",
    "    while right < len(code):\n",
    "        if code[right] == ' ':\n",
    "            postion_mapping.append((left, right))\n",
    "            left = right + 1\n",
    "        right += 1\n",
    "\n",
    "    # add the last token\n",
    "    postion_mapping.append((left, right))\n",
    "    code = [\"<s>\"]\n",
    "    extended_types = []\n",
    "    left = 0\n",
    "    for node in tree:\n",
    "        # rewrite code\n",
    "        node = str(node).split(' ')\n",
    "        if node[1] == '\"MASK\"':\n",
    "            code.append('<mask>')\n",
    "        else:\n",
    "            code.append(node[1][1:-1])\n",
    "        # extend types\n",
    "        left = int(node[-1]) -1\n",
    "        right = left + len(node[1][1:-1])\n",
    "        # check (left, right) in postion_mapping and get the index\n",
    "        for i in range(len(postion_mapping)):\n",
    "            if left >= postion_mapping[i][0] and right <= postion_mapping[i][1]:\n",
    "                extended_types.append([types[i], node[1]])\n",
    "                break\n",
    "    code.append(\"</s>\")\n",
    "    return extended_types, ' '.join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ast_types(code):\n",
    "    code = code.replace(\"{\", \" {\")\n",
    "    code = \" \".join(code.split())\n",
    "    code_list = code.split(' ')\n",
    "    tree = parser.parse(bytes(code, \"utf8\"))\n",
    "    root_node = tree.root_node\n",
    "    declaration = traverse(root_node)\n",
    "    types = label_tokens(code_list, declaration)\n",
    "\n",
    "    ast_types, rewrote_code = get_extended_types(code_list, types)\n",
    "    return ast_types, rewrote_code\n",
    "\n",
    "code = \"class Simple{ public static void main(String args[]){ System.out.println( 'Hello Java'); }}\"\n",
    "ast_types, rewrote_code = get_ast_types(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 27)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ast_types), len(rewrote_code.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_declaration': [['class', 'Simple']], 'method_declaration': [['public', 'static', 'void', 'main(String', 'args[])']]}\n",
      "['class_declaration', 'class_declaration', 'other', 'method_declaration', 'method_declaration', 'method_declaration', 'method_declaration', 'method_declaration', 'other', 'other', 'other', 'other', 'other']\n"
     ]
    }
   ],
   "source": [
    "# code = \"class Simple{ public static void main(String args[]){ System.out.println( 'Hello Java'); }}\"\n",
    "\n",
    "# code = code.replace(\"{\", \" {\")\n",
    "# code = \" \".join(code.split())\n",
    "# code_list = code.split(' ')\n",
    "\n",
    "# tree = parser.parse(bytes(code, \"utf8\"))\n",
    "\n",
    "# root_node = tree.root_node\n",
    "# # declaration = {}\n",
    "# declaration = traverse(root_node)\n",
    "# print(declaration)\n",
    "# types = label_tokens(code_list, declaration)\n",
    "# print(types)\n",
    "\n",
    "# if len(types) != len(code_list):\n",
    "#     print(\"Error: the number of tokens is not equal to the number of labels\")\n",
    "\n",
    "# ast_types = get_extended_types(code_list, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['class_declaration', '\"class\"'],\n",
       " ['class_declaration', '\"Simple\"'],\n",
       " ['other', '\"{\"'],\n",
       " ['method_declaration', '\"public\"'],\n",
       " ['method_declaration', '\"static\"'],\n",
       " ['method_declaration', '\"void\"'],\n",
       " ['method_declaration', '\"main\"'],\n",
       " ['method_declaration', '\"(\"'],\n",
       " ['method_declaration', '\"String\"'],\n",
       " ['method_declaration', '\"args\"'],\n",
       " ['method_declaration', '\"[\"'],\n",
       " ['method_declaration', '\"]\"'],\n",
       " ['method_declaration', '\")\"'],\n",
       " ['other', '\"{\"'],\n",
       " ['other', '\"System\"'],\n",
       " ['other', '\".\"'],\n",
       " ['other', '\"out\"'],\n",
       " ['other', '\".\"'],\n",
       " ['other', '\"println\"'],\n",
       " ['other', '\"(\"'],\n",
       " ['other', '\"\\'Hello'],\n",
       " ['other', '\")\"'],\n",
       " ['other', '\";\"'],\n",
       " ['other', '\"}\"'],\n",
       " ['other', '\"}\"']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"../dataset/valid.txt\"\n",
    "postfix=file_path.split('/')[-1].split('.txt')[0]\n",
    "index_filename=file_path\n",
    "url_to_code={}\n",
    "with open('/'.join(index_filename.split('/')[:-1])+'/data.jsonl') as f:\n",
    "    for line in f:\n",
    "        line=line.strip()\n",
    "        js=json.loads(line)\n",
    "        url_to_code[js['idx']]=js['func']\n",
    "data=[]\n",
    "cache={}\n",
    "f=open(index_filename)\n",
    "with open(index_filename) as f:\n",
    "    lines = 1000\n",
    "    added_lines = 0\n",
    "    for line in f:\n",
    "        # control number of read data \n",
    "        if added_lines >= lines:\n",
    "            break\n",
    "        line=line.strip()\n",
    "        url1,url2,label=line.split('\\t')\n",
    "        if url1 not in url_to_code or url2 not in url_to_code:\n",
    "            continue\n",
    "        if label=='0':\n",
    "            label=0\n",
    "        else:\n",
    "            label=1\n",
    "        data.append((url1,url2,label,' '.join(url_to_code[url1].split()), ' '.join(url_to_code[url2].split())))\n",
    "        added_lines += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_types(types):\n",
    "    # check the index of first second value is the \"{\"\n",
    "    if types[0][1] == '\"class\"':\n",
    "        return ['[CLS]'] + types + ['[SEP]']\n",
    "    index_ = 0\n",
    "    # if not class declaration, find the first \"{\" and add method_declaration before it\n",
    "    for i in range(len(types)):\n",
    "        if types[i][1] == '\"{\"':\n",
    "            index_ = i\n",
    "            break\n",
    "    final_types = [] \n",
    "    final_types.append('[CLS]')\n",
    "    for i in range(len(types)):\n",
    "        if i < index_:\n",
    "            final_types.append(\"method_declaration\")\n",
    "        else:\n",
    "            final_types.append(types[i][0])\n",
    "    final_types.append('[SEP]')\n",
    "\n",
    "    return final_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_syntax_types_for_code(code_snippet):\n",
    "  types = [\"[CLS]\"]\n",
    "  code = [\"<s>\"]\n",
    "  tree = list(javalang.tokenizer.tokenize(code_snippet))\n",
    "  \n",
    "  for i in tree:\n",
    "    j = str(i)\n",
    "    j = j.split(\" \")\n",
    "    if j[1] == '\"MASK\"':\n",
    "      types.append('[MASK]')\n",
    "      code.append('<mask>')\n",
    "    else:\n",
    "      types.append(j[0].lower())\n",
    "      code.append(j[1][1:-1])\n",
    "    \n",
    "  types.append(\"[SEP]\")\n",
    "  code.append(\"</s>\")\n",
    "  return np.array(types), ' '.join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = data[50][4]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    code = data[i][3]\n",
    "    types = get_ast_types(code)\n",
    "    final_types = convert(types)\n",
    "    types_1, rewrote_code_1 = get_syntax_types_for_code(code)\n",
    "\n",
    "    if len(final_types) != len(types_1):\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'method_declaration',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " 'other',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique types \n",
    "unique = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    code = data[i][3]\n",
    "    types = get_ast_types(code)\n",
    "    final_types = convert(types)\n",
    "\n",
    "    for j in range(len(final_types)):\n",
    "        if final_types[j] not in unique:\n",
    "            unique.append(final_types[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'method_declaration',\n",
       " 'other',\n",
       " '[SEP]',\n",
       " 'if_statement',\n",
       " 'else',\n",
       " 'field_declaration',\n",
       " 'class_declaration',\n",
       " 'constructor_declaration']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast_syntaxes = ['method_declaration', 'if_statement', 'else', 'class_declaration', 'constructor_declaration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1] + [2, 3, 4] + [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CodeBert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b13e3fd3289f8bb387fc7ab81946cd58b1691644cd9d3c76126fbd09f58dbdd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
